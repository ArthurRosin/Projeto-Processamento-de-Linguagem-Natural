{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArthurRosin/Projeto-Processamento-de-Linguagem-Natural/blob/main/pnlProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2024-Q2]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m67OOx9MX_3"
      },
      "source": [
        "### **PROJETO PRÁTICO** [LangChain + Grandes Modelos de Linguagem + API]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gk0nHKabBT-"
      },
      "source": [
        "O **PROJETO PRÁTICO** deve ser feito utilizando o **Google Colab** com uma conta sua vinculada ao Gmail. O link do seu notebook, armazenado no Google Drive, o link de um repositório no GitHub e o link de um vídeo do projeto em execução detalhando os principais resultados da atividade, devem ser enviados usando o seguinte formulário:\n",
        "\n",
        "\n",
        "> Adicionar blockquote\n",
        "\n",
        "\n",
        "> https://forms.gle/D4gLqP1iGgyn2hbH8\n",
        "\n",
        "\n",
        "**IMPORTANTE**: A submissão deve ser feita até o dia **08/09 (domingo)** APENAS POR UM INTEGRANTE DA EQUIPE, até às 23h59. Por favor, lembre-se de dar permissão de ACESSO IRRESTRITO para o professor da disciplina de PLN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hJlilKM485"
      },
      "source": [
        "### **EQUIPE**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnIArN0QY-Ek"
      },
      "source": [
        "**POR FAVOR, PREENCHER OS INTEGRANDES DA SUA EQUIPE:**\n",
        "\n",
        "\n",
        "**Integrante 01:** Arthur Rio Verde Melo Rosin - 11202020257\n",
        "\n",
        "\n",
        "**Integrante 02:** Davi Nunes de Paiva - 11202231636\n",
        "\n",
        "\n",
        "**Integrante 03:** Lucas Tanino Pellegrini - 11202232020\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbYD2mw8y4CN"
      },
      "source": [
        "### **GRANDE MODELO DE LINGUAGEM (*Large Language Model - LLM*)**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UlblxFxzDV-"
      },
      "source": [
        "Cada equipe deve selecionar um Grande Modelo de Linguagem (*Large Language Model - LMM*). Cada modelo pode ser escolhido por até 5 equipes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6AkE6iW0c3o"
      },
      "source": [
        "Por favor, informe os dados do LLM selecionada:\n",
        "\n",
        ">\n",
        "\n",
        "\n",
        "**LLM**: ChatGPT 4.0\n",
        "\n",
        ">\n",
        "\n",
        "**Link para a documentação oficial**: [Site documentação oficial ChatGPT 4.0](https://platform.openai.com/docs/models)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yExhaebs-nD"
      },
      "source": [
        "### **API**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjJM_qhEZRy6"
      },
      "source": [
        "Por favor, informe os dados da API selecionada:\n",
        "\n",
        "**API**: OpenAI API\n",
        "\n",
        "**Site oficial**: [Site oficial OpenIA](https://platform.openai.com/docs/overview)\n",
        "\n",
        "**Link para a documentação oficial**: [Site documentação oficial OpenIA API](https://platform.openai.com/docs/overview)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTODq98Myt_u"
      },
      "source": [
        "**IMPORTANTE**: cada **API** pode ser usada por até 4 equipes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtjgWQRzNphL"
      },
      "source": [
        "### **DESCRIÇÃO**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXTwkiiGs2BV"
      },
      "source": [
        "Implementar um `notebook` no `Google Colab` que faça uso do framework **`LangChain`** (obrigatório) e de um **LLM** aplicando, no mínimo, DUAS técnicas de PLN. As técnicas podem ser aplicada em qualquer córpus obtido a partir de uma **API** ou a partir de uma página Web.\n",
        "\n",
        "O **LLM** e a **API** selecionados devem ser informados na seguinte planilha:\n",
        "\n",
        "> https://docs.google.com/spreadsheets/d/1iIUZcwnywO7RuF6VEJ8Rx9NDT1cwteyvsnkhYr0NWtU/edit?usp=sharing\n",
        "\n",
        ">\n",
        "As seguintes técnicas de PLN podem ser usadas:\n",
        "\n",
        "*   Correção Gramatical\n",
        "*   Classificação de Textos\n",
        "*   Análise de Sentimentos\n",
        "*   Detecção de Emoções\n",
        "*   Extração de Palavras-chave\n",
        "*   Tradução de Textos\n",
        "*   Sumarização de Textos\n",
        "*   Similaridade de Textos\n",
        "*   Reconhecimento de Entidades Nomeadas\n",
        "*   Sistemas de Perguntas e Respostas\n",
        ">\n",
        "\n",
        "**IMPORTANTE:** É obrigatório usar o e-mail da UFABC.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iHdx4BXYruQ"
      },
      "source": [
        "Serão considerados como critérios de avaliação os seguintes pontos:\n",
        "\n",
        "* Uso do framework **`LangChain`**.\n",
        "\n",
        "* Escolha e uso de um **LLM**.\n",
        "\n",
        "* Escolha e uso de uma **API**.\n",
        "\n",
        "* Vídeo (5 a 10 minutos).\n",
        "\n",
        "* Criatividade no uso do framework **`LangChain`** em conjunto com o **LLM** e a **API**.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhwdrMp123Xx"
      },
      "source": [
        "**IMPORTANTE**: todo o código do notebook deve ser executado. Código sem execução não será considerado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw09lujGvfjc"
      },
      "source": [
        "### **IMPLEMENTAÇÃO**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O código tem como objetivo a criação de um agente de RAG (Retrieval-Augmented Generation) usando LangChain, que utiliza um modelo de linguagem para interagir com várias ferramentas e fontes externas para melhorar a qualidade das respostas geradas.\n",
        "\n",
        "O que são agentes LangChain?\n",
        "\n",
        "Um agente LangChain é um componente que utiliza um modelo de linguagem para interagir com outras ferramentas e realizar ações para cumprir uma tarefa ou objetivo.\n",
        "\n",
        "Como funcionam os agentes LangChain?\n",
        "\n",
        "Os agentes utilizam um Modelo de Linguagem como um mecanismo de raciocínio para determinar quais ações ou ferramentas usar e em que ordem para alcançar o resultado desejado.\n",
        "\n",
        "Os agentes têm acesso a um conjunto de ferramentas que fornecem diferentes capacidades como pesquisa na web, consulta de banco de dados, chamadas de API, cálculos, etc.\n",
        "\n",
        "O agente utiliza o LM para analisar a tarefa dada, decidir quais ferramentas são necessárias, executar as ferramentas, observar os resultados e repetir o processo até que a tarefa seja concluída.\n",
        "\n",
        "Demonstrando o conceito de agentes Langchain, que usam um modelo de linguagem como um mecanismo de raciocínio para selecionar e executar ferramentas de um conjunto predefinido, como pesquisa na web, consulta de banco de dados e chamadas de API.\n",
        "\n",
        "O agente RAG (Retrieval Augmented Generation) é capaz de determinar dinamicamente as ações necessárias para completar uma tarefa.Também apresenta a criação de um agente ReAct (Reasoning and Action) que pode invocar ferramentas como SerpAPI, ArXiv e Wikipedia para responder a consultas.\n",
        "\n",
        "Por que utilizar os Modelos Rag?\n",
        "\n",
        "Os modelos RAG, que combinam a recuperação de informações externas com as capacidades do modelo de linguagem, superam as limitações dos dados de treinamento iniciais. Eles sugerem que o processo de tomada de decisão dinâmico dos agentes LangChain é superior às sequências predefinidas de ações, oferecendo maior flexibilidade e adaptabilidade. O uso de agentes LangChain pode levar a saídas mais precisas e confiáveis, especialmente para tarefas intensivas em conhecimento."
      ],
      "metadata": {
        "id": "m5BSxBP5-_4K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primeiramente, vamos instalar algumas das bibliotecas que serão utilizadas ao longo do código:"
      ],
      "metadata": {
        "id": "Hr8af0Hj_Dk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langgraph langchain langchain-openai langchainhub langchain-community pypdf faiss-cpu arxiv wikipedia tavily-python google-search-results httpx"
      ],
      "metadata": {
        "id": "fRpeGKxi_EAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora, iremos preparar a chave API da OpenIA, para que seja acessível para o atual sistema."
      ],
      "metadata": {
        "id": "KS67gMvt_JA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
      ],
      "metadata": {
        "id": "66PENXb3_JjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregando o LLM e o modelo de Embeddings.\n",
        "\n",
        "Em seguida, carregaremos o último modelo GPT-4o da OpenAI e seu modelo de embeddings. Definiremos a temperatura para zero."
      ],
      "metadata": {
        "id": "sbIZJZxT_Lfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Loading model and embedder\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "embedder = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "BU3oRl6I_L0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando um Retriever\n",
        "\n",
        "Agora, carregaremos um artigo do repositório Arxiv que fornece uma pesquisa sobre os diversos algoritmos RAG. Em seguida, dividiremos este documento em pedaços menores usando o \"RecursiveCharacterTextSplitter\", armazenaremos os embeddings em um armazenamento vetorial \"FAISS\" usando o embedder e, criaremos um objeto retriever retriever_paper.\n",
        "\n",
        "Também converteremos este retriever em uma ferramenta usando \"create_retriever_tool\" para que possa ser usado por um agente mais tarde."
      ],
      "metadata": {
        "id": "8jYeCrmr_Ufq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"https://arxiv.org/pdf/2312.10997\")\n",
        "paper = loader.load()"
      ],
      "metadata": {
        "id": "pf0UQ-cU_Uy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "# splitting text from the PDF document into smaller chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        ")\n",
        "\n",
        "chunks_paper = text_splitter.split_documents(paper)\n"
      ],
      "metadata": {
        "id": "4EPjxts9_XQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing in vector store\n",
        "faiss_db_paper = FAISS.from_documents(chunks_paper, embedder)\n",
        "# creating retriever\n",
        "retriever_paper = faiss_db_paper.as_retriever()"
      ],
      "metadata": {
        "id": "NhJT07cI_Xke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregando Ferramentas\n",
        "\n",
        "Agora, carregaremos várias ferramentas para pesquisa na web, incluindo SerpAPI, ArXiv e Wikipedia. OBS: será necessario adquirir uma chave de API para SerpAPI(gratuita)."
      ],
      "metadata": {
        "id": "61genAAx_bo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## converting the retriever to a Tool\n",
        "\n",
        "from langchain.tools.retriever import create_retriever_tool\n",
        "\n",
        "retriever_tool = create_retriever_tool(retriever_paper, \"RAG doc\", \"Search for info on RAG\")"
      ],
      "metadata": {
        "id": "VrzbCK2j_lXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Load multiple tools\n",
        "\n",
        "from langchain_community.utilities import ArxivAPIWrapper\n",
        "from langchain_community.tools.wikipedia.tool import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "\n",
        "# arxiv tool\n",
        "arxiv =  ArxivAPIWrapper()\n",
        "\n",
        "# wikipedia tool\n",
        "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())"
      ],
      "metadata": {
        "id": "qzTGQE_z_mRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## api key for tools\n",
        "\n",
        "# serpapi\n",
        "os.environ['SERPAPI_API_KEY']=getpass.getpass()\n",
        "# tavily perai\n",
        "os.environ['TAVILY_API_KEY']=getpass.getpass()"
      ],
      "metadata": {
        "id": "gk3FKAUx_nkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Langchain api key\n",
        "LANGCHAIN_TRACING_V2=\"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ['LANGCHAIN_API_KEY']=getpass.getpass()"
      ],
      "metadata": {
        "id": "LUx7guIH_oaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_community.utilities import SerpAPIWrapper\n",
        "\n",
        "# tavily tool\n",
        "tavily = TavilySearchResults(max_results=1)\n",
        "\n",
        "# serpapi tool\n",
        "serpapi = SerpAPIWrapper()"
      ],
      "metadata": {
        "id": "2D3mNoeA_poR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando um Executor de Ferramentas\n",
        "\n",
        "Iremos definir essas ferramentas de acordo com um modelo específico. O modelo permite que o ToolExecutor do LangGraph execute essas ferramentas. Ele requer três parâmetros: func, name e description.\n",
        "\n",
        "func é a função que será chamada quando a ferramenta for invocada. name é uma string representando o nome da ferramenta. description é uma breve descrição da funcionalidade da ferramenta. Este parâmetro é muito importante, pois o raciocínio sobre qual ferramenta será usada depende da descrição. Adotando este modelo, podemos integrar perfeitamente nossas ferramentas ao fluxo de trabalho do LangGraph e utilizar o ToolExecutor para executá-las conforme necessário. Na lista de ferramentas, também incluiremos o retriever_tool que criamos anteriormente."
      ],
      "metadata": {
        "id": "OL-ZvYqP_rUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import Tool\n",
        "\n",
        "## A proper name and a good description helps to know on how to use the tools, otherwise ToolExecutor will not work\n",
        "wiki_tool = Tool.from_function(\n",
        "    func=wikipedia.run,\n",
        "    name=\"wiki\",\n",
        "    description=\"useful for when you need to search certain topic on Wikipedia, aka wiki\")\n",
        "\n",
        "arxiv_tool = Tool.from_function(\n",
        "    func=arxiv.run,\n",
        "    name=\"arxiv\",\n",
        "    description=\"useful for querying from arxiv repository\")\n",
        "\n",
        "tavily_tool = Tool.from_function(\n",
        "    func= tavily.invoke,\n",
        "    name = 'tavily',\n",
        "    description = 'Search Engine'\n",
        ")\n",
        "\n",
        "serpapi_tool = Tool.from_function(\n",
        "    func= serpapi.run,\n",
        "    name = 'serpapi',\n",
        "    description = 'Search Engine'\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# List of all tools\n",
        "tools = [wiki_tool, arxiv_tool, tavily_tool, serpapi_tool, retriever_tool]"
      ],
      "metadata": {
        "id": "hAKuHmZ9_r2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt.tool_executor import ToolExecutor, ToolInvocation # reinstall langgraph if fails!\n",
        "\n",
        "# This a helper class we have that is useful for running tools\n",
        "# It takes in an agent action and calls that tool and returns the result\n",
        "tool_executor = ToolExecutor(tools)"
      ],
      "metadata": {
        "id": "m9R6fDz-_vCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## PROMPT TEMPLATE\n",
        "\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "## set up memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key='input', output_key=\"output\")\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "### [INST]\n",
        "\n",
        "Assistant is a large language model to answer questions on Retrieval Augmented Generation.\n",
        "\n",
        "\n",
        "Context:\n",
        "------\n",
        "\n",
        "Assistant has access to the following tools:\n",
        "\n",
        "{tools}\n",
        "\n",
        "To use a tool, please use the following format:\n",
        "\n",
        "'''\n",
        "Thought: Do I need to use a tool? Yes\n",
        "Action: the action to take, should be one of [{tool_names}]\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "'''\n",
        "\n",
        "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
        "\n",
        "'''\n",
        "Thought: Do I need to use a tool? No\n",
        "Final Answer: [your response here]\n",
        "'''\n",
        "\n",
        "Begin!\n",
        "\n",
        "Previous conversation history:\n",
        "{chat_history}\n",
        "\n",
        "New input: {input}\n",
        "\n",
        "Current Scratchpad:\n",
        "{agent_scratchpad}\n",
        "\n",
        "[/INST]\n",
        " \"\"\"\n",
        "\n",
        "# Create prompt from prompt template\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=['agent_scratchpad', 'chat_history', 'input', 'tool_names', 'tools'],\n",
        "    template=prompt_template,\n",
        ")\n",
        "\n",
        "prompt = prompt.partial(\n",
        "    tools=[t.name for t in tools],\n",
        "    tool_names=\", \".join([t.name for t in tools]),\n",
        ")\n",
        "print(\"prompt ---> \\n\", prompt)"
      ],
      "metadata": {
        "id": "iOyJzB_j_5qZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando um Agente ReAct\n",
        "\n",
        "Esta parte do código demonstra como criar um Agente ReAct, que é um agente LangChain que segue o framework de Razão e Ação (ReAct) para resolver tarefas complexas selecionando e executando ferramentas apropriadas com base em suas descrições.\n",
        "\n",
        "Os aspectos principais de um Agente ReAct são:\n",
        "\n",
        "Razão: O agente utiliza um LLM (Modelo de Linguagem Grande) para raciocinar sobre qual ferramenta é apropriada para o passo atual da tarefa, com base nas descrições das ferramentas.\n",
        "\n",
        "Ação: O agente executa a ferramenta selecionada com a entrada especificada. Observação: O agente observa a saída da ferramenta executada.\n",
        "\n",
        "Prompt ReAct\n",
        "\n",
        "Vamos primeiro importar um modelo de prompt ReAct do LangChain Hub. O modelo aceita os seguintes valores de entrada:\n",
        "\n",
        "agent_scratchpad: Provavelmente uma string que representa os pensamentos iniciais ou o contexto do agente antes de iniciar o processo de raciocínio.\n",
        "\n",
        "input: É a consulta original ou a tarefa que o agente precisa resolver.\n",
        "\n",
        "tool_names: Uma lista de nomes das ferramentas disponíveis que o agente pode usar.\n",
        "\n",
        "tools: Uma lista de descrições das ferramentas, fornecendo informações sobre a funcionalidade de cada uma.\n",
        "\n",
        "Ele especifica o formato em que o agente deve estruturar sua resposta, incluindo seções para:\n",
        "\n",
        "Pergunta: A pergunta original de entrada.\n",
        "\n",
        "Pensamento: Os pensamentos iniciais ou raciocínio do agente.\n",
        "\n",
        "Ação: A ação a ser tomada, que deve ser uma das ferramentas disponíveis.\n",
        "\n",
        "Entrada de Ação: A entrada a ser fornecida à ferramenta selecionada.\n",
        "\n",
        "Observação: A saída ou resultado da execução da ferramenta selecionada.\n",
        "\n",
        "Resposta Final: A resposta final à pergunta original de entrada."
      ],
      "metadata": {
        "id": "HbqOn7PfAVgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating React Agent\n",
        "from langchain import hub\n",
        "\n",
        "# Get the prompt to use - you can modify this!\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "k8nzn3MJAWM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora, iremos criar a instância do agente ReAct usando \"create_react_agent\" que recebe um LLM, um conjunto de ferramentas e o prompt, enquanto AgentExecutor fornece uma maneira de executar essa instância do agente com as ferramentas e entrada especificadas. Os dois componentes trabalham juntos para criar e executar um agente ReAct no LangChain."
      ],
      "metadata": {
        "id": "_ytudPKYAYJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor, create_react_agent\n",
        "\n",
        "# Construct the ReAct agent\n",
        "agent = create_react_agent(model, tools, prompt)\n",
        "\n",
        "# Create an agent executor by passing in the agent and tools\n",
        "agent_executor = AgentExecutor(agent=agent,\n",
        "                               tools=tools,\n",
        "                               verbose=True,\n",
        "                               handle_parsing_errors=True,\n",
        "                               max_iterations=3,\n",
        "                               return_intermediate_steps=True,\n",
        "                               early_stopping_method=\"generate\")"
      ],
      "metadata": {
        "id": "vsmyYA89AZrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora, vamos fazer uma pergunta sobre RAG. O agente agora está usando a ferramenta RAG doc."
      ],
      "metadata": {
        "id": "Xd5PFs7tAa3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test it !\n",
        "agent_outcome = agent_executor.invoke({\"input\": \"what is Adaptive RAG?\",\"chat_history\": []})\n",
        "agent_outcome"
      ],
      "metadata": {
        "id": "a0JVztiTAcCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assim como a função run_agent, esta função também recebe dados como entrada, que é o estado atual do gráfico. Ela recupera o agent_outcome do estado, que contém as ações ou etapas intermediárias sugeridas pelo agente.\n",
        "\n",
        "Se houver etapas intermediárias (ações) no agent_outcome, a função extrai a primeira ação (agent_action) e invoca o tool_executor com essa ação. A saída da execução da ferramenta é então retornada como parte do novo estado sob a chave \"intermediate_steps\", juntamente com a ação original.\n",
        "\n",
        "Se não houver etapas intermediárias no agent_outcome, a função simplesmente retorna uma lista vazia para \"intermediate_steps\"."
      ],
      "metadata": {
        "id": "lhJLGRQAAdyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent_action = agent_outcome['intermediate_steps'][0][0]\n",
        "output = tool_executor.invoke(agent_action)\n",
        "agent_action"
      ],
      "metadata": {
        "id": "azJfW69SAulR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estado do Agente:\n",
        "\n",
        "No LangGraph, o estado do agente é representado por um objeto que contém todas as informações e dados relevantes à situação ou contexto atual do agente. Este objeto de estado é passado para cada nó no gráfico.\n",
        "\n",
        "Agora, quando um nó é executado, ele pode atualizar ou modificar o estado de duas maneiras:\n",
        "\n",
        "SET (Definir): O nó pode sobrescrever ou substituir atributos específicos (propriedades) do objeto de estado por novos valores. Isso é como mudar completamente certas partes do estado do agente.ADD (Adicionar): O nó pode adicionar novas informações ou dados a atributos existentes do objeto de estado, sem sobrescrever os valores anteriores. Isso é como anexar ou estender o estado atual do agente com detalhes adicionais. Se um nó deve SET (sobrescrever) ou ADD (anexar) aos atributos do objeto de estado é determinado por como você define ou anota o objeto de estado quando constrói o gráfico.\n",
        "\n",
        "Vamos definir o estado para o Agente LangChain."
      ],
      "metadata": {
        "id": "gkVS8T3VAxP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create agent state class\n",
        "\n",
        "from typing import TypedDict, Annotated, List, Union\n",
        "from langchain_core.agents import AgentAction, AgentFinish\n",
        "from langchain_core.messages import BaseMessage\n",
        "import operator\n",
        "\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    # The input string\n",
        "    input: str\n",
        "    # The list of previous messages in the conversation\n",
        "    chat_history: list[BaseMessage]\n",
        "    # The outcome of a given call to the agent\n",
        "    # Needs `None` as a valid type, since this is what this will start as\n",
        "    agent_outcome: Union[AgentAction, AgentFinish, None]\n",
        "    # List of actions and corresponding observations\n",
        "    # Here we annotate this with `operator.add` to indicate that operations to\n",
        "    # this state should be ADDED to the existing values (not overwrite it)\n",
        "    intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]"
      ],
      "metadata": {
        "id": "xY8qee4LAzqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora, vamos definir os dois nós principais em nosso gráfico; o nó do agente e o nó de execução da ferramenta.\n",
        "\n",
        "Primeiro, o nó do agente contém a função run_agent que define o comportamento do nó \"agente\" no LangGraph. Seu objetivo é invocar o agente (neste caso, agent_executor) com o texto de entrada dado e recuperar o resultado do agente. O resultado do agente normalmente inclui as ações que o agente deseja realizar ou o resultado final."
      ],
      "metadata": {
        "id": "8JqT_uV4A0xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the nodes\n",
        "from langchain_core.agents import AgentActionMessageLog\n",
        "\n",
        "def run_agent(data):\n",
        "    inputs = data.copy()\n",
        "    text = inputs['input']\n",
        "    # chat_history = inputs['chat_history']\n",
        "    agent_outcome = agent_executor.invoke({\"input\":text}) #, \"chat_history\": chat_history\n",
        "    return {\"agent_outcome\": agent_outcome}\n",
        "\n",
        "# Define the function to execute tools\n",
        "def execute_tools(data):\n",
        "    # Get the most recent agent_outcome - this is the key added in the `agent` above\n",
        "    agent_output = data[\"agent_outcome\"]\n",
        "    if len(agent_output['intermediate_steps'])>=1 :\n",
        "        agent_action = agent_output['intermediate_steps'][0][0]\n",
        "        output = tool_executor.invoke(agent_action)\n",
        "        return {\"intermediate_steps\": [(agent_action, str(output))]}\n",
        "    else:\n",
        "        return {\"intermediate_steps\":[]}\n",
        "\n",
        "# Define logic that is used to determine which conditional edge to go down\n",
        "def should_continue(data):\n",
        "    # If the agent outcome is an AgentFinish, then we return `exit` string\n",
        "    # This will be used when setting up the graph to define the flow\n",
        "    if data[\"agent_outcome\"][\"output\"] is not None:\n",
        "        print(\" **AgentFinish** \" )\n",
        "        return \"end\"\n",
        "    # Otherwise, an AgentAction is returned\n",
        "    # Here we return `continue` string\n",
        "    # This will be used when setting up the graph to define the flow\n",
        "    else:\n",
        "        print(\" **continue** \" )\n",
        "        return \"continue\""
      ],
      "metadata": {
        "id": "0Gjq3fh9A2es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código define um fluxo de trabalho LangGraph que cicla entre um nó \"agente\" e um nó \"ação\" (execução de ferramenta), com uma borda condicional que determina se o fluxo de trabalho deve continuar ou terminar com base no resultado do agente."
      ],
      "metadata": {
        "id": "g1YTcPfZA5E6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END, StateGraph\n",
        "\n",
        "# Define a new graph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Define the two nodes we will cycle between\n",
        "workflow.add_node(\"agent\", run_agent)\n",
        "workflow.add_node(\"action\", execute_tools)\n",
        "\n",
        "# Set the entrypoint as `agent`\n",
        "# This means that this node is the first one called\n",
        "workflow.set_entry_point(\"agent\")\n",
        "\n",
        "# We now add a conditional edge\n",
        "workflow.add_conditional_edges(\n",
        "    # First, we define the start node. We use `agent`.\n",
        "    # This means these are the edges taken after the `agent` node is called.\n",
        "    \"agent\",\n",
        "    # Next, we pass in the function that will determine which node is called next.\n",
        "    should_continue,\n",
        "    # Finally we pass in a mapping.\n",
        "    # The keys are strings, and the values are other nodes.\n",
        "    # END is a special node marking that the graph should finish.\n",
        "    # What will happen is we will call `should_continue`, and then the output of that\n",
        "    # will be matched against the keys in this mapping.\n",
        "    # Based on which one it matches, that node will then be called.\n",
        "    {\n",
        "        # If `tools`, then we call the tool node.\n",
        "        \"continue\": \"action\",\n",
        "        # Otherwise we finish.\n",
        "        \"end\": END,\n",
        "    },\n",
        ")\n",
        "\n",
        "# We now add a normal edge from `tools` to `agent`.\n",
        "# This means that after `tools` is called, `agent` node is called next.\n",
        "workflow.add_edge(\"action\", \"agent\")\n",
        "\n",
        "# Finally, we compile it!\n",
        "# This compiles it into a LangChain Runnable,\n",
        "# meaning you can use it as you would any other runnable\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "NsyGEtEuGhMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora vamos testar o código.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nBj7h85XGjBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"input\": \"Explain Adaptive Retrieval methods\"} # ,\"chat_history\": []\n",
        "outputs = app.invoke(inputs)"
      ],
      "metadata": {
        "id": "LRQ1RpMGGjq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs['agent_outcome']['output']"
      ],
      "metadata": {
        "id": "nmVPANc7Gl3I"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}